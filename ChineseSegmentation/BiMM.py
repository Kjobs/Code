# -*- coding: utf-8 -*- 

# 加载测试语料  
def load_corpus():
    corpusText = '''长春生产的卧铺动车组面世，在零下40℃的环境下，也可以长时间运营。
最先组装好的两列动车组，可能用在从哈尔滨开往武汉、深圳方向的线路上。
常出门的人都知道，坐高铁出行快确实是快，可是也有不尽如人意的地方，比如只能坐不能躺、手机上网信号不稳定、 卫生间少、噪音大等等。
现在好了，长春生产的卧铺动车组面世，上面的问题全部能够解决！因为前部两个车灯就像两个可爱的“黑眼圈”，所以，这种动车被称为“熊猫”，不过它的速度比熊猫快得多，时速可达250公里。
白天能坐 晚上能卧
昨天上午，在中车长客股份公司的厂房内，静卧着两列已组装好的动车组，它们的编号分别是CRH5E-5201和CRH5E-5202。
卧铺动车组设计经理毕凯说，CRH5E作为国内唯一一款可以在高寒和风沙条件下运行的卧铺动车组，可以在零下40℃的环境下长时间运营。
它具备简洁实用的“座卧转换”功能，可实现夜间卧、白天坐两种运营模式。
从坐到卧，是怎么实现的呢？车头、车尾的车厢，仍是普通动车组的座位安排。
不过中间的车厢除了餐车，都是能实现“座卧转换”功能的“包厢”。
包厢里面，在白天的时候，上铺的床板不是平铺的，有60度的斜角。
毕凯解释说，这样能保证在座位状态下，上铺有空间放置被褥、枕头，也不会给坐在下铺位置的乘客压迫感。
那么会不会出现松动，床板变成平铺的情况呢？
毕凯说，处于斜拉状态时，上铺的床板都是被卡住的，要变成平铺，需要列车员用专门的钥匙打开，所以这一点不用担心。
下铺的座位跟一般动车组的座位没啥区别，躺着似乎有些紧凑。
毕凯演示了一下，变成卧铺时，座位板是可以向外拉伸的，有20厘米左右的空间。
同时，一块原本靠在车厢板的板块就能铺平这个空隙。
再躺上，就足够宽敞了。
电源插座多 随时连Wi-Fi
常坐火车的人旅途无聊时，都喜欢玩手机，可总担心手机没电。
在车厢里，新文化记者特别留意了电源插座的设置。
靠窗的位置找到两个；靠近包厢门内侧，挨着上铺的位置又找到两个。
就连床头灯都有两个USB插口设置，电脑、手机等电子设备充电续航是一点问题都没有。
更让人开心的时，不只可以充电，还可以随时连接Wi-Fi上网。
在下铺的下面，能看到一个白色的圆盒子，这就是Wi-Fi天线，上了车，旅客可以随时随地实现上网功能。
“这可是普通动车组所没有的功能，再也不用担心旅途无聊了！”
此外，很多人坐火车时，经常遇到卫生间排队的情况。
而在这个动车组上，每节车厢有3个卫生间，可以减少排队等候的时间，洗手盆也设置了2个。
噪音低 不超过65分贝
有乘客担心，时速250公里，躺着睡觉，噪音会不会让人睡不着啊？
毕凯说，为了能让乘客享有安静的睡眠环境，列车通过吸音、隔声、阻尼、减振和密封等五大技术对车辆内部噪声进行严格控制。
即使列车在以每小时250公里的速度前进时，客室的噪音也不超过65分贝，比飞机在空中飞行时的声音低出20分贝。
车辆摇晃也是干扰睡眠的一大因素，这在设计的时候也考虑到了，CRH5E具有抗侧风优势，即使外面狂风呼啸，乘客在车厢内也不会感到明显的晃动。
动车组的车窗玻璃具有“减速”功能，光线可以透过玻璃均匀折射，喜欢看风景的旅客也不必担心速度过快而头晕目眩。
为了确保安全，列车还配置了目前世界上最先进的故障诊断和远程监控系统。
通过各种传感器对列车的关键系统和部位的温度、速度、加速度、压力、绝缘性能等进行实时监控，可实时根据限定数值进行自动控制列车运行速度，做到安全出行。
同时，车厢内设有火灾自动报警系统，列车可根据情况自动降速和自动停车，确保旅客的乘车安全。

首站吉尔吉斯斯坦，吉国家通讯社卡巴尔通讯社引用本国政治评论家的话说，李总理的访问将巩固中吉战略伙伴关系。
哈萨克斯坦，塔斯社、埃菲社、俄罗斯卫星网均给予报道称，哈总统纳扎尔巴耶夫认为中国是重要的战略伙伴，赞赏中哈关系是国与国友好合作的典范。
俄罗斯列格努姆通讯社引用拉脱维亚外交部的说法称。
俄罗斯卫星网报道称，梅德韦杰夫在与李克强会晤时表示，俄中既是合作伙伴又是友邦，莫斯科愿与北京讨论任何中方感兴趣的问题。
外媒也十分关注李克强出席上海合作组织成员国政府首脑（总理）理事会第十五次会议。
路透社和法国国际广播电台不约而同注意到，李克强总理在会议上表示，中国愿与上合组织成员国加强安全领域的协调合作。
国际媒体尤其关注中国-中东欧“16+1”合作机制，认为这有助于中东欧的和平、稳定和发展。
路透社、埃菲社、BBC均关注此次中国-中东欧国家领导人会晤期间，中方倡议成立的中国-中东欧金融控股有限公司正式挂牌。
德国《明镜》周刊网站报道说，中东欧国家在“16+1”峰会上一致认为，无论如何都要加强和中国的合作。
美国、德国及俄罗斯媒体聚焦于中俄双方此次签订的能源、交通运输等“大项目”。

忙活半个小时
还是很有成就感的
已经失去了自我控制能力～我真想扒开那些孩子的大脑看看里面装的都是啥！能不能聪明点
这里怎么一点烟味都闻不到
再看我，我就把你吃掉
采买+做+摆盘+拍照已然耗光所有力气…… 除了萝卜泡菜不是我做的，其他都是！本来没想做这么多的！
小小的人，背着大大的贝斯。
这，瓢泼大雨。看了朋友圈其他人的惨痛教训，果断穿短裤出门，到公司换条长裤穿上
月亮有光晕，超级美。外面凉快得让人想“露宿街头”～
好喜欢吃他家卤肉饭，继三里屯店、中关村店后的又一家：芳草地店… 不知道集齐会发生什么～ 终于去吃了幸菓，他家空调不太好
起床晚了，不过今天通勤车完全没堵，11分钟到公司～ 今天尝了这个雀巢饼，对，没错，我也不知道为什么叫这个名字… 但是挺好吃的！
三天之后要交的论文，然而憋了一个上午?一个下午却只写完文献综述.都是以前毕业论文偷懒没有写翻译的债啊，出来混该还的迟早要还 学术这条道路真的不适合我，那么美好的周末只能码字了。'''
    return corpusText.decode('utf-8')

def load_rightdic(filename):
    with open(filename, 'r') as f:
        dictFile = f.read()
        rightDict = dictFile.decode('utf-8').split('\n')
        dictList = list(set(rightDict))
        dictList.sort(key = rightDict.index)
    return dictList

# 加载测试用词典
def load_dict(filename):  
    dicFile = open(filename,'r').read()  
    maxLen = 1  
    strList = dicFile.decode('utf-8').split('\n')
    #print strList

    for i in strList:
        if len(i) > maxLen:
            maxLen = len(i) 

    return strList, maxLen

# 正向最大匹配
def forward_segmentation(strList,maxLen,sentence):
    wordList = []
    oneword = 0
    # sentence = sentence.decode('utf-8')
  
    while(len(sentence) > 0):
        word = sentence[0:maxLen]

        meet = False;  
  
        while((not meet) and (len(word)>0)):
            #word = word.encode('utf-8').decode('utf-8')
            if word in strList: 
                if len(word) == 1:
                    oneword += 1 
                wordList.append(word) 
                sentence = sentence[len(word):len(sentence)] 
                meet = True;  
            else:
                if(len(word) == 1):
                    oneword += 1 
                    wordList.append(word)
                    sentence = sentence[len(word):len(sentence)]  
                    meet = True;  
                else:
                    word = word[0:len(word)-1]
    return wordList, oneword

#逆向最大匹配
def backward_segmentation(strList,maxLen,sentence):
    wordList = []
    oneword = 0
    # sentence = sentence.decode('utf-8') 
    while(len(sentence) > 0):
        word = sentence[len(sentence)-maxLen:len(sentence)]

        meet = False;  
  
        while((not meet) and (len(word)>0)):
            # word = word.encode('utf-8').decode('utf-8')
            if word in strList:
                if len(word) == 1:
                    oneword += 1
                wordList.append(word) 
                sentence = sentence[0:len(sentence)-len(word)] 
                meet = True;  
            else:
                if(len(word) == 1):
                    oneword += 1
                    wordList.append(word)
                    sentence = sentence[0:len(sentence)-len(word)]  
                    meet = True;  
                else:
                    word = word[1:len(sentence)] 
    return wordList, oneword   

# 计算分词结果的正确率与召回率
def Precision_Recall_rate(word_List):
    punctuation_list = ['',u'？',u'，',u'。',u'、','\r\n',u'～',u'……',' ',u'！',u'…',u'（',u'）',u'“',u'”',u'《',u'》','.',u'：','?']
    for word in word_List:
        if word in punctuation_list:
            word_List.remove(word)
    realNum = 0

    rightList = load_rightdic('rightdic.txt')
    realList = list(set(word_List))

    for i in realList:
        if i in rightList:
            realNum += 1;
    # 准确率
    Precision_rate = float(realNum) / len(realList)
    # 召回率
    Recall_rate = float(realNum) / len(rightList)

    return Precision_rate, Recall_rate

#将分词结果输出到Output.txt文件
def result_write(word_List, filename):
    punctuation_list = ['',u'？',u'，',u'。',u'、','\r\n',u'～',u'……',' ',u'！',u'…',u'（',u'）',u'“',u'”',u'《',u'》','.',u'：','?']
    for word in word_List:
        if word in punctuation_list:
            word_List.remove(word)
    with open(filename, 'w') as f:
        for eachword in word_List:
                eachword = eachword.encode('gbk')
                f.write(eachword + '\n')

def main():
    forward_word = []
    backward_word = []

    strList, maxLen=load_dict('dic.txt')
    print "Max_Length of dict: ",maxLen  
    
    corpusText = load_corpus()
    length = len(corpusText)  
    print 'Length of corpus: ',length
    print "================="
    forward_word, FMM_oneword = forward_segmentation(strList, maxLen, corpusText)
    Precision_rate1, Recall_rate1 = Precision_Recall_rate(forward_word)
    print "Reuslt of FMM"
    print "-------------------------------"
    print "precision_rate:",Precision_rate1
    print "recall_rate:",Recall_rate1
    FMM_len = len(forward_word)
    backward_word, BMM_oneword = backward_segmentation(strList, maxLen, corpusText)
    Precision_rate2, Recall_rate2 = Precision_Recall_rate(backward_word)
    print "Result of BMM"
    print "-------------------------------"
    print "precision_rate:",Precision_rate2
    print "recall_rate:",Recall_rate2
    BMM_len = len(backward_word)

    # print the result by different segmentation
    if FMM_len > BMM_len:
        print "Result of segmentation is FMM better than BMM(FMM_len > BMM_len)."
        result_write(forward_word, 'Output.txt')
    elif FMM_len < BMM_len:
        "Result of segmentation is BMM better than FMM(FMM_len < BMM_len)."
        result_write(backward_word[::-1], 'Output.txt')
    else:
        if FMM_oneword > BMM_oneword:
            "Result of segmentation is FMM better than BMM(FMM_oneword > BMM_oneword)."
            result_write(forward_word, 'Output.txt')
        else:
            "Result of segmentation is BMM better than FMM()."
            result_write(backward_word[::-1], 'Output.txt') 

  
if __name__ == '__main__':
    main()
